{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ceb513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from open_clip import get_tokenizer\n",
    "from open_clip.transform import image_transform_v2, PreprocessCfg\n",
    "import webdataset as wds\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import Imagenette, ImageFolder, DTD\n",
    "import torch.nn as nn\n",
    "\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "from src.clipn import CLIPNAdapter, AltCLIPNAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838b81ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "checkpoint = torch.load(\"/repo/ALTMEDCLIPN/checkpoints/PMC_model_cosine/latest_checkpoint.pth\", weights_only=False)[\"model_state_dict\"]\n",
    "\n",
    "model = AltCLIPNAdapter(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    \"text.transformer.encoder\"\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca07e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully:\n",
      "Dataset({\n",
      "    features: ['image', 'labels'],\n",
      "    num_rows: 23828\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Allows loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Load the test split of the dataset\n",
    "full_dataset = load_dataset(\n",
    "    \"alkzar90/NIH-Chest-X-ray-dataset\", \n",
    "    \"image-classification\", \n",
    "    # cache_dir=\"/repo/MEDCLIPN/data/NIH_chest\", \n",
    "    split=\"test\"\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded successfully:\")\n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13bc50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created with correct pathology columns:\n",
      "                                               image  No Finding  Atelectasis  \\\n",
      "0  {'bytes': None, 'path': '/root/.cache/huggingf...           0            0   \n",
      "1  {'bytes': None, 'path': '/root/.cache/huggingf...           0            0   \n",
      "2  {'bytes': None, 'path': '/root/.cache/huggingf...           0            0   \n",
      "3  {'bytes': None, 'path': '/root/.cache/huggingf...           0            0   \n",
      "4  {'bytes': None, 'path': '/root/.cache/huggingf...           0            0   \n",
      "\n",
      "   Cardiomegaly  Effusion  Infiltration  Mass  Nodule  Pneumonia  \\\n",
      "0             0         0             0     0       0          0   \n",
      "1             0         0             0     0       0          0   \n",
      "2             0         0             0     0       0          0   \n",
      "3             0         0             1     0       0          0   \n",
      "4             0         0             0     0       0          0   \n",
      "\n",
      "   Pneumothorax  Consolidation  Edema  Emphysema  Fibrosis  \\\n",
      "0             0              0      0          0         0   \n",
      "1             0              0      0          0         0   \n",
      "2             0              0      0          0         0   \n",
      "3             0              0      0          0         0   \n",
      "4             0              0      0          0         0   \n",
      "\n",
      "   Pleural_Thickening  Hernia  \n",
      "0                   0       1  \n",
      "1                   0       1  \n",
      "2                   0       1  \n",
      "3                   0       1  \n",
      "4                   0       1  \n"
     ]
    }
   ],
   "source": [
    "# Get the names of the pathology labels from the dataset's features\n",
    "pathology_names = full_dataset.features['labels'].feature.names\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = full_dataset.to_pandas()\n",
    "\n",
    "# CORRECTED LOGIC:\n",
    "# Create a binary column for each pathology.\n",
    "# A row gets a '1' if the pathology's index is in the 'labels' list, and '0' otherwise.\n",
    "for i, name in enumerate(pathology_names):\n",
    "    df[name] = df['labels'].apply(lambda label_indices: 1 if i in label_indices else 0)\n",
    "\n",
    "# Drop the original 'labels' column as it's no longer needed\n",
    "df = df.drop(columns=['labels'])\n",
    "\n",
    "print(\"DataFrame created with correct pathology columns:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05db50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Distribution Pathologies:\n",
      "['No Finding', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation']\n",
      "\n",
      "Out-of-Distribution Pathologies:\n",
      "['Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n"
     ]
    }
   ],
   "source": [
    "# Use the pathology names from the dataset, excluding 'No Finding' for the split\n",
    "NIH_PATHOLOGIES = pathology_names\n",
    "\n",
    "# First 7 pathologies for in-distribution (ID)\n",
    "ID_PATHOLOGIES = NIH_PATHOLOGIES[:10]\n",
    "# Remaining pathologies for out-of-distribution (OOD)\n",
    "OOD_PATHOLOGIES = NIH_PATHOLOGIES[10:]\n",
    "\n",
    "print(\"In-Distribution Pathologies:\")\n",
    "print(ID_PATHOLOGIES)\n",
    "print(\"\\nOut-of-Distribution Pathologies:\")\n",
    "print(OOD_PATHOLOGIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cb8abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test set size: 23828\n",
      "In-distribution (ID) set size: 20599\n",
      "Out-of-distribution (OOD) set size: 1044\n"
     ]
    }
   ],
   "source": [
    "# Create the in-distribution (ID) dataframe\n",
    "# Condition: No OOD pathologies are present (value is not 1)\n",
    "ood_clean = ~df[OOD_PATHOLOGIES].eq(1).any(axis=1)\n",
    "id_df = df[ood_clean].reset_index(drop=True)\n",
    "\n",
    "# Create the out-of-distribution (OOD) dataframe\n",
    "# Condition 1: At least one OOD pathology is present (value is 1)\n",
    "ood_positive = df[OOD_PATHOLOGIES].eq(1).any(axis=1)\n",
    "# Condition 2: No ID pathologies are present (value is not 1)\n",
    "id_clean = ~df[ID_PATHOLOGIES].eq(1).any(axis=1)\n",
    "ood_df = df[ood_positive & id_clean].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original test set size: {len(df)}\")\n",
    "print(f\"In-distribution (ID) set size: {len(id_df)}\")\n",
    "print(f\"Out-of-distribution (OOD) set size: {len(ood_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1e184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, pathologies, transform=None):\n",
    "        self.transform = transform\n",
    "        self.pathologies = pathologies\n",
    "        self.classes = pathologies\n",
    "        self.image_paths = dataframe['image'].apply(lambda x: x['path']).tolist()\n",
    "        labels_df = dataframe[self.pathologies]\n",
    "        self.labels = torch.tensor(labels_df.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871596a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets and DataLoaders created successfully:\n",
      "ID Dataset: <__main__.NIHChestXrayDataset object at 0x7ff2d02b1fc0>\n",
      "OOD Dataset: <__main__.NIHChestXrayDataset object at 0x7ff2d0293d30>\n"
     ]
    }
   ],
   "source": [
    "# Create in-distribution dataset (id_dataset)\n",
    "chest_in_dataset = NIHChestXrayDataset(\n",
    "    dataframe=id_df,\n",
    "    pathologies=ID_PATHOLOGIES,\n",
    "    transform=preprocess\n",
    ")\n",
    "\n",
    "# Create out-of-distribution dataset (ood_dataset)\n",
    "chest_out_dataset = NIHChestXrayDataset(\n",
    "    dataframe=ood_df,\n",
    "    pathologies=OOD_PATHOLOGIES,\n",
    "    transform=preprocess\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "chest_in_loader = DataLoader(\n",
    "    chest_in_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "chest_out_loader = DataLoader(\n",
    "    chest_out_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\nDatasets and DataLoaders created successfully:\")\n",
    "print(f\"ID Dataset: {chest_in_dataset}\")\n",
    "print(f\"OOD Dataset: {chest_out_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770ac9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac_atlas_dataset = ImageFolder(\"/repo/MEDCLIPN/data/FracAtlas_dataset/images\", transform=preprocess)\n",
    "# isic_dataset = ImageFolder(\"/repo/MEDCLIPN/data/ISIC2020_test_dataset\", transform=preprocess)\n",
    "\n",
    "# frac_atlas_dataloader = DataLoader(\n",
    "#     frac_atlas_dataset,\n",
    "#     batch_size = 32,\n",
    "#     shuffle = False,\n",
    "#     num_workers = 1,\n",
    "#     pin_memory = True\n",
    "# )\n",
    "\n",
    "# isic_dataloader = DataLoader(\n",
    "#     isic_dataset,\n",
    "#     batch_size = 32,\n",
    "#     shuffle = False,\n",
    "#     num_workers=1,\n",
    "#     pin_memory = True\n",
    "# )\n",
    "\n",
    "ood_loaders = {\n",
    "    \"chest_xray\": chest_out_loader,\n",
    "    # \"frac_atlas\": frac_atlas_dataloader,\n",
    "    # \"isic2020\": isic_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0d32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_yes_no_feature(dataset, model, tokenizer, device):\n",
    "    txt = []\n",
    "    N = len(dataset.classes)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    if N:\n",
    "        with open(\"/repo/MEDCLIPN/src/prompt/med_prompt.txt\") as f:\n",
    "            prompt_lis = f.readlines()\n",
    "        num_prom = len(prompt_lis)\n",
    "    for idx in range(num_prom):\n",
    "        for name in dataset.classes:\n",
    "            txt.append(tokenizer(prompt_lis[idx].replace(\"\\n\", \"\").format(name)).unsqueeze(0))\n",
    "    txt = torch.cat(txt, dim=0)\n",
    "    txt = txt.reshape(num_prom, len(dataset.classes), -1)\n",
    "    text_inputs = txt.to(device)\n",
    "    \n",
    "    text_yes_ttl = torch.zeros(len(dataset.classes), 512).to(device)\n",
    "    text_no_ttl = torch.zeros(len(dataset.classes), 512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_prom):\n",
    "            text_yes_i = model.encode_text(text_inputs[i], normalize=True)\n",
    "            text_no_i = model.encode_text_no(text_inputs[i])\n",
    "            text_no_i = F.normalize(text_no_i, dim=-1)\n",
    "            \n",
    "            text_yes_ttl += text_yes_i\n",
    "            text_no_ttl += text_no_i\n",
    "            \n",
    "    return F.normalize(text_yes_ttl, dim=-1), F.normalize(text_no_ttl, dim=-1)\n",
    "\n",
    "class ViT_Classifier(torch.nn.Module):\n",
    "    def __init__(self, image_encoder, classification_head_yes, classification_head_no):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        flag = True\n",
    "        self.fc_yes = nn.Parameter(classification_head_yes, requires_grad=flag)    # num_classes  num_feat_dimension\n",
    "        self.fc_no = nn.Parameter(classification_head_no, requires_grad=flag)      # num_classes  num_feat_dimension\n",
    "        self.scale = 100. # this is from the parameter of logit scale in CLIPN\n",
    "        \n",
    "    def set_frozen(self, module):\n",
    "        for module_name in module.named_parameters():\n",
    "            module_name[1].requires_grad = False\n",
    "    def set_learnable(self, module):\n",
    "        for module_name in module.named_parameters():\n",
    "            module_name[1].requires_grad = True\n",
    "            \n",
    "    def forward(self, x):\n",
    "        inputs = self.image_encoder(x)\n",
    "        inputs_norm = F.normalize(inputs, dim=-1)\n",
    "        fc_yes = F.normalize(self.fc_yes, dim=-1)\n",
    "        fc_no = F.normalize(self.fc_no, dim=-1)\n",
    "        \n",
    "        logits_yes = self.scale * inputs_norm @ fc_yes.T \n",
    "        logits_no = self.scale * inputs_norm @ fc_no.T\n",
    "        return logits_yes, logits_no, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1723005",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fff, no_fff = merge_yes_no_feature(chest_in_dataset, model, model.tokenizer, \"cuda\")\n",
    "clipn_classifier = ViT_Classifier(model.visual, yes_fff, no_fff)\n",
    "clipn_classifier.fc_yes.requires_grad = False\n",
    "clipn_classifier.fc_no.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa661d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy import interpolate\n",
    "\n",
    "def maybe_dictionarize(batch):\n",
    "    if isinstance(batch, dict):\n",
    "        return batch\n",
    "\n",
    "    if len(batch) == 2:\n",
    "        batch = {'images': batch[0], 'labels': batch[1]}\n",
    "    elif len(batch) == 3:\n",
    "        batch = {'images': batch[0], 'labels': batch[1], 'metadata': batch[2]}\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected number of elements: {len(batch)}')\n",
    "\n",
    "    return batch\n",
    "\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "def max_logit_score(logits):\n",
    "    return to_np(torch.max(logits, -1)[0])\n",
    "def msp_score(logits):\n",
    "    prob = torch.softmax(logits, -1)\n",
    "    return to_np(torch.max(prob, -1)[0])\n",
    "def energy_score(logits):\n",
    "    return to_np(torch.logsumexp(logits, -1))\n",
    "\n",
    "\n",
    "def cal_all_metric(id_dataset, model, epoch, ood_dataset=None, flag=True):\n",
    "    model.eval()\n",
    "    \n",
    "    # ADDED: Make code device-agnostic (works on CPU or GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # --- In-Distribution (ID) Data Evaluation ---\n",
    "    id_logits_all = []\n",
    "    id_labels_all = []\n",
    "    \n",
    "    ind_scores = {\n",
    "        \"MaxLogit\": [],\n",
    "        \"MSP\": [],\n",
    "        \"Energy\": [],\n",
    "        \"CTW\": [],\n",
    "        \"ATD\": []\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(id_dataset, desc=\"Evaluating on ID data\"):\n",
    "            batch = maybe_dictionarize(batch)\n",
    "            inputs = batch[\"images\"].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits, logits_no, _ = model(inputs)\n",
    "            \n",
    "            # CHANGED: Collect raw logits and labels for proper multi-label evaluation\n",
    "            id_logits_all.append(logits.detach().cpu())\n",
    "            id_labels_all.append(labels.detach().cpu())\n",
    "\n",
    "            # Collect OOD detection scores for ID samples\n",
    "            ind_scores[\"MaxLogit\"].extend(max_logit_score(logits))\n",
    "            ind_scores[\"MSP\"].extend(msp_score(logits))\n",
    "            ind_scores[\"Energy\"].extend(energy_score(logits))\n",
    "            \n",
    "            if flag:\n",
    "                idex = torch.argmax(logits, -1).unsqueeze(-1)\n",
    "                yesno = torch.softmax(torch.cat([logits.unsqueeze(-1), logits_no.unsqueeze(-1)], -1), dim=-1)[:, :, 0]\n",
    "                yesno_s = torch.gather(yesno, dim=1, index=idex)\n",
    "                ind_scores[\"CTW\"].extend(to_np(yesno_s))\n",
    "                ind_scores[\"ATD\"].extend(to_np((yesno * torch.softmax(logits, -1)).sum(1)))\n",
    "\n",
    "    # CHANGED: Concatenate all batch results once for efficiency\n",
    "    id_logits_all = torch.cat(id_logits_all)\n",
    "    id_labels_all = torch.cat(id_labels_all)\n",
    "\n",
    "    # CHANGED: Calculate a proper multi-label classification metric (Area Under ROC Curve)\n",
    "    # This correctly evaluates the model's ability to identify each of the multiple possible pathologies.\n",
    "    id_probs = torch.sigmoid(id_logits_all)\n",
    "    # Using 'micro' averaging treats each sample-label pair as an individual prediction, suitable for this task.\n",
    "    id_auc_micro = roc_auc_score(to_np(id_labels_all), to_np(id_probs), average='micro')\n",
    "    \n",
    "    id_lis_epoch = [[epoch, id_auc_micro]]\n",
    "    \n",
    "    # --- Out-of-Distribution (OOD) Data Evaluation ---\n",
    "    ood_lis_epoch = []\n",
    "    if ood_dataset:\n",
    "        for name, ood_data in ood_dataset.items():\n",
    "            ood_scores = {\n",
    "                \"MaxLogit\": [],\n",
    "                \"MSP\": [],\n",
    "                \"Energy\": [],\n",
    "                \"CTW\": [],\n",
    "                \"ATD\": []\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(ood_data, desc=f\"Evaluating on OOD data: {name}\"):\n",
    "                    batch = maybe_dictionarize(batch)\n",
    "                    inputs = batch[\"images\"].to(device)\n",
    "                    \n",
    "                    logits, logits_no, _ = model(inputs)\n",
    "\n",
    "                    ood_scores[\"MaxLogit\"].extend(max_logit_score(logits))\n",
    "                    ood_scores[\"MSP\"].extend(msp_score(logits))\n",
    "                    ood_scores[\"Energy\"].extend(energy_score(logits))\n",
    "            \n",
    "                    if flag:\n",
    "                        idex = torch.argmax(logits, -1).unsqueeze(-1)\n",
    "                        yesno = torch.softmax(torch.cat([logits.unsqueeze(-1), logits_no.unsqueeze(-1)], -1), dim=-1)[:, :, 0]\n",
    "                        yesno_s = torch.gather(yesno, dim=1, index=idex)\n",
    "                        ood_scores[\"CTW\"].extend(to_np(yesno_s))\n",
    "                        ood_scores[\"ATD\"].extend(to_np((yesno * torch.softmax(logits, -1)).sum(1)))\n",
    "\n",
    "            # Calculate OOD detection metrics\n",
    "            score_map = {\"MSP\": \"MSP\", \"MaxLogit\": \"MaxLogit\", \"Energy\": \"Energy\", \"CTW\": \"CTW\", \"ATD\": \"ATD\"}\n",
    "            for score_key, report_name in score_map.items():\n",
    "                if not flag and score_key in [\"CTW\", \"ATD\"]:\n",
    "                    continue\n",
    "                \n",
    "                auc, fpr = cal_auc_fpr(ind_scores[score_key], ood_scores[score_key])\n",
    "                ood_lis_epoch.append([epoch, report_name, name, auc, fpr])\n",
    "\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    print(f\"Epoch {epoch} In-Distribution (ID) Micro-AUC: {id_lis_epoch[0][1]:.4f}\")\n",
    "    for lis in ood_lis_epoch:\n",
    "        print(f\"Epoch {lis[0]}, Method: {lis[1]:<10}, OOD Set: {lis[2]:<10}, AUROC: {lis[3]:.4f}, FPR@95TPR: {lis[4]:.4f}\")\n",
    "        \n",
    "    return id_lis_epoch, ood_lis_epoch\n",
    "\n",
    "\n",
    "def cal_auc_fpr(ind_conf, ood_conf):\n",
    "    conf = np.concatenate((ind_conf, ood_conf))\n",
    "    ind_indicator = np.concatenate((np.ones_like(ind_conf), np.zeros_like(ood_conf)))\n",
    "    auroc = metrics.roc_auc_score(ind_indicator, conf)\n",
    "    fpr,tpr,thresh = roc_curve(ind_indicator, conf, pos_label=1)\n",
    "    fpr = float(interpolate.interp1d(tpr, fpr)(0.95))\n",
    "    return auroc, fpr\n",
    "\n",
    "def cal_fpr_recall(ind_conf, ood_conf, tpr=0.95):\n",
    "    conf = np.concatenate((ind_conf, ood_conf))\n",
    "    ind_indicator = np.concatenate((np.ones_like(ind_conf), np.zeros_like(ood_conf)))\n",
    "    fpr,tpr,thresh = roc_curve(ind_indicator, conf, pos_label=1)\n",
    "    fpr = float(interpolate.interp1d(tpr, fpr)(0.95))\n",
    "    return fpr, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c5aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on ID data: 100%|██████████| 644/644 [04:35<00:00,  2.33it/s]\n",
      "Evaluating on OOD data: chest_xray: 100%|██████████| 33/33 [00:13<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Epoch 1 In-Distribution (ID) Micro-AUC: 0.4188\n",
      "Epoch 1, Method: MSP       , OOD Set: chest_xray, AUROC: 0.4814, FPR@95TPR: 0.9483\n",
      "Epoch 1, Method: MaxLogit  , OOD Set: chest_xray, AUROC: 0.5001, FPR@95TPR: 0.9454\n",
      "Epoch 1, Method: Energy    , OOD Set: chest_xray, AUROC: 0.5017, FPR@95TPR: 0.9444\n",
      "Epoch 1, Method: CTW       , OOD Set: chest_xray, AUROC: 0.5033, FPR@95TPR: 0.9470\n",
      "Epoch 1, Method: ATD       , OOD Set: chest_xray, AUROC: 0.5134, FPR@95TPR: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = cal_all_metric(chest_in_loader, clipn_classifier, 1, ood_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073cc876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b064 caption {\n",
       "  font-size: 16px;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_0b064_row0_col0, #T_0b064_row0_col1, #T_0b064_row1_col0, #T_0b064_row1_col1, #T_0b064_row2_col0, #T_0b064_row2_col1, #T_0b064_row3_col0, #T_0b064_row3_col1, #T_0b064_row4_col0, #T_0b064_row4_col1 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b064\">\n",
       "  <caption>OOD Detection Performance Comparison</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b064_level0_col0\" class=\"col_heading level0 col0\" >('AUROC (chest_xray)',)</th>\n",
       "      <th id=\"T_0b064_level0_col1\" class=\"col_heading level0 col1\" >('FPR95 (chest_xray)',)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b064_level0_row0\" class=\"row_heading level0 row0\" >MSP</th>\n",
       "      <td id=\"T_0b064_row0_col0\" class=\"data row0 col0\" >0.48</td>\n",
       "      <td id=\"T_0b064_row0_col1\" class=\"data row0 col1\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b064_level0_row1\" class=\"row_heading level0 row1\" >MaxLogit</th>\n",
       "      <td id=\"T_0b064_row1_col0\" class=\"data row1 col0\" >0.50</td>\n",
       "      <td id=\"T_0b064_row1_col1\" class=\"data row1 col1\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b064_level0_row2\" class=\"row_heading level0 row2\" >Energy</th>\n",
       "      <td id=\"T_0b064_row2_col0\" class=\"data row2 col0\" >0.50</td>\n",
       "      <td id=\"T_0b064_row2_col1\" class=\"data row2 col1\" >0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b064_level0_row3\" class=\"row_heading level0 row3\" >CTW</th>\n",
       "      <td id=\"T_0b064_row3_col0\" class=\"data row3 col0\" >0.50</td>\n",
       "      <td id=\"T_0b064_row3_col1\" class=\"data row3 col1\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b064_level0_row4\" class=\"row_heading level0 row4\" >ATD</th>\n",
       "      <td id=\"T_0b064_row4_col0\" class=\"data row4 col0\" >0.51</td>\n",
       "      <td id=\"T_0b064_row4_col1\" class=\"data row4 col1\" >0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff29cbe5a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_comparison_table(results):\n",
    "    df = pd.DataFrame(results, columns=['epoch', 'method', 'dataset', 'auroc', 'fpr95'])\n",
    "    \n",
    "    # Create multi-index table\n",
    "    metrics_table = df.pivot_table(\n",
    "        index='method',\n",
    "        columns='dataset',\n",
    "        values=['auroc', 'fpr95'],\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    \n",
    "    # Sort methods in meaningful order\n",
    "    method_order = ['MSP', 'MaxLogit', 'Energy', 'CTW', 'ATD']\n",
    "    metrics_table = metrics_table.reindex(method_order)\n",
    "    \n",
    "    # Format numbers and column names\n",
    "    metrics_table = metrics_table.round(2)\n",
    "    metrics_table.columns = pd.MultiIndex.from_tuples([\n",
    "        (f\"{metric.upper()} ({dataset})\" if dataset else metric.upper(),)\n",
    "        for metric, dataset in metrics_table.columns\n",
    "    ])\n",
    "    \n",
    "    # Apply styling\n",
    "    styled_df = metrics_table.style \\\n",
    "        .set_caption(\"OOD Detection Performance Comparison\") \\\n",
    "        .format(\"{:.2f}\") \\\n",
    "        .set_properties(**{'text-align': 'center'}) \\\n",
    "        .set_table_styles([{\n",
    "            'selector': 'caption',\n",
    "            'props': [('font-size', '16px'), ('font-weight', 'bold')]\n",
    "        }])\n",
    "    \n",
    "    return styled_df\n",
    "\n",
    "create_comparison_table(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed956cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALTMEDCLIPN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
